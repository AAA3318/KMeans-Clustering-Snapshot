{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from the Dataset Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_DIRECTORY = './datasets/'\n",
    "\n",
    "symbol_dfs = {}\n",
    "\n",
    "for filename in os.listdir(DATASET_DIRECTORY):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(DATASET_DIRECTORY, filename)\n",
    "\n",
    "        # Read the csv file using pandas\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        symbol = filename.split('.')[0]\n",
    "        symbol_dfs[symbol] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove starting year is greater than 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in list(symbol_dfs.keys()): \n",
    "    df = symbol_dfs[symbol]  \n",
    "\n",
    "    if 'Date' in df.columns: \n",
    "        df.drop(columns=['Date'], inplace=True)  \n",
    "\n",
    "    if 'Time' in df.columns: \n",
    "        df['Time'] = pd.to_datetime(df['Time'])  \n",
    "\n",
    "    # Remove if the starting year is greater than 2008  \n",
    "    if df['Time'][0].year > 2008:  \n",
    "        del symbol_dfs[symbol]  \n",
    "    else:  \n",
    "        symbol_dfs[symbol] = df  \n",
    "\n",
    "symbols = list(symbol_dfs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncate as the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = min([len(symbol_dfs[symbol]) for symbol in symbol_dfs])\n",
    "\n",
    "for symbol, df in symbol_dfs.items():\n",
    "    symbol_dfs[symbol] = df.iloc[-min_len:]\n",
    "    symbol_dfs[symbol] = symbol_dfs[symbol].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate LogR and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for symbol, df in symbol_dfs.items():\n",
    "\n",
    "    # Calculate Log Return from Close price\n",
    "    df['LogR'] = np.log(df['Close']) - np.log(df['Close'].shift(1))\n",
    "\n",
    "    # Median filtering\n",
    "    df['LogR'] = df['LogR'].fillna(df['LogR'].median())\n",
    "\n",
    "    # Normalize the LogR column\n",
    "    scaler = StandardScaler()\n",
    "    df['LogR'] = scaler.fit_transform(df[['LogR']])\n",
    "\n",
    "    symbol_dfs[symbol] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List to hold LogR columns from all symbols\n",
    "logr_list  = []\n",
    "\n",
    "# Loop through each symbol and its corresponding DataFrame\n",
    "for symbol, df in symbol_dfs.items():\n",
    "    # Extract the LogR column and convert it to a numpy array\n",
    "    logr_column = df['LogR'].values  # This converts the 'LogR' column to a numpy array\n",
    "    logr_list.append(logr_column)\n",
    "\n",
    "# Stack the list of arrays into a 2D numpy array (symbol_n * column_length)\n",
    "returns_data  = np.vstack(logr_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering with DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Elbow Method to find optimal number of clusters\n",
    "max_clusters = 14\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range(2, max_clusters + 1):\n",
    "    print(\"Cluster number: \", n_clusters)\n",
    "    model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", random_state=0)\n",
    "    clusters = model.fit_predict(returns_data)\n",
    "    \n",
    "    # Store inertia (sum of distances to the closest cluster center)\n",
    "    clusters = model.fit_predict(returns_data)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    score = silhouette_score(returns_data, clusters, metric=\"euclidean\")  # Silhouette score with Euclidean distance\n",
    "    silhouette_scores.append(score)\n",
    "    \n",
    "    # Group symbols by cluster\n",
    "    cluster_dict = {i: [] for i in range(n_clusters)}\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        cluster_dict[cluster].append(symbols[i])\n",
    "    \n",
    "    # Print symbols for each cluster\n",
    "    for cluster, sym_list in cluster_dict.items():\n",
    "        print(f\"Cluster {cluster}: {', '.join(sym_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_clusters = np.argmax(silhouette_scores) + 2  # Adding 2 because the range starts from 2 clusters\n",
    "\n",
    "print(f\"Optimal number of clusters based on silhouette score: {optimal_clusters}\")\n",
    "\n",
    "# Refit the model using the optimal number of clusters\n",
    "model = TimeSeriesKMeans(n_clusters=optimal_clusters, metric=\"dtw\", random_state=0)\n",
    "optimal_clusters_labels = model.fit_predict(returns_data)\n",
    "\n",
    "# Group symbols by optimal clusters and print\n",
    "optimal_cluster_dict = {i: [] for i in range(optimal_clusters)}\n",
    "for i, cluster in enumerate(optimal_clusters_labels):\n",
    "    optimal_cluster_dict[cluster].append(symbols[i])\n",
    "\n",
    "# Print symbols for each optimal cluster\n",
    "for cluster, sym_list in optimal_cluster_dict.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(sym_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
